{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzfanRDGhzqSuKa+Aze3YS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DLhp81FegLOP"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_df = pd.read_csv(\"fake_or_real_news.csv\")"
      ],
      "metadata": {
        "id": "vXdlp-TKuDX4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = list(text_df.text.values)\n",
        "joined_text = \" \".join(text)"
      ],
      "metadata": {
        "id": "5Vkpt_Gs5Snh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "partical_text = joined_text[:10000]"
      ],
      "metadata": {
        "id": "ymtK6yah6m9q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "tokens = tokenizer.tokenize(partical_text.lower())"
      ],
      "metadata": {
        "id": "neOgmYGd6w_z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_tokens = np.unique(tokens)\n",
        "unique_tokens_index = {token: idx for idx, token in enumerate(unique_tokens)}"
      ],
      "metadata": {
        "id": "_3G-1gOY7UJB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_words = 10\n",
        "input_words = []\n",
        "next_words = []\n",
        "\n",
        "for i in range(len(tokens) - n_words):\n",
        "  input_words.append(tokens[i:i + n_words])\n",
        "  next_words.append(tokens[i + n_words])"
      ],
      "metadata": {
        "id": "EEyEzrIS9m3w"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(input_words), n_words, len(unique_tokens)), dtype=bool)\n",
        "y = np.zeros((len(next_words), len(unique_tokens)), dtype=bool)"
      ],
      "metadata": {
        "id": "uhogM8zF-QhX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, words in enumerate(input_words):\n",
        "  for j, word in enumerate(words):\n",
        "    x[i, j, unique_tokens_index[word]] = 1\n",
        "  y[i, unique_tokens_index[next_words[i]]] = 1"
      ],
      "metadata": {
        "id": "SIOhqY5f_u8M"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(n_words, len(unique_tokens)), return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(len(unique_tokens)))\n",
        "model.add(Activation(\"softmax\"))"
      ],
      "metadata": {
        "id": "602nBkKQATKF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(learning_rate=0.01), metrics=[\"accuracy\"])\n",
        "model.fit(x, y, batch_size=128, epochs=30, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQiDY8bPCTWp",
        "outputId": "4185349b-fea0-4a38-dd24-0bb16f9ebc6e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "14/14 [==============================] - 8s 102ms/step - loss: 6.1995 - accuracy: 0.0458\n",
            "Epoch 2/30\n",
            "14/14 [==============================] - 1s 99ms/step - loss: 5.8468 - accuracy: 0.0618\n",
            "Epoch 3/30\n",
            "14/14 [==============================] - 1s 100ms/step - loss: 5.7964 - accuracy: 0.0618\n",
            "Epoch 4/30\n",
            "14/14 [==============================] - 1s 102ms/step - loss: 5.7858 - accuracy: 0.0618\n",
            "Epoch 5/30\n",
            "14/14 [==============================] - 1s 102ms/step - loss: 5.7516 - accuracy: 0.0618\n",
            "Epoch 6/30\n",
            "14/14 [==============================] - 2s 170ms/step - loss: 5.7182 - accuracy: 0.0618\n",
            "Epoch 7/30\n",
            "14/14 [==============================] - 2s 117ms/step - loss: 5.6788 - accuracy: 0.0595\n",
            "Epoch 8/30\n",
            "14/14 [==============================] - 1s 99ms/step - loss: 5.5865 - accuracy: 0.0618\n",
            "Epoch 9/30\n",
            "14/14 [==============================] - 1s 102ms/step - loss: 5.4954 - accuracy: 0.0646\n",
            "Epoch 10/30\n",
            "14/14 [==============================] - 1s 105ms/step - loss: 5.3642 - accuracy: 0.0635\n",
            "Epoch 11/30\n",
            "14/14 [==============================] - 1s 102ms/step - loss: 5.1631 - accuracy: 0.0749\n",
            "Epoch 12/30\n",
            "14/14 [==============================] - 1s 102ms/step - loss: 4.9626 - accuracy: 0.0818\n",
            "Epoch 13/30\n",
            "14/14 [==============================] - 1s 101ms/step - loss: 4.7470 - accuracy: 0.0932\n",
            "Epoch 14/30\n",
            "14/14 [==============================] - 2s 161ms/step - loss: 4.4601 - accuracy: 0.1173\n",
            "Epoch 15/30\n",
            "14/14 [==============================] - 2s 125ms/step - loss: 4.2999 - accuracy: 0.1379\n",
            "Epoch 16/30\n",
            "14/14 [==============================] - 1s 101ms/step - loss: 3.8847 - accuracy: 0.1619\n",
            "Epoch 17/30\n",
            "14/14 [==============================] - 1s 104ms/step - loss: 3.5652 - accuracy: 0.1791\n",
            "Epoch 18/30\n",
            "14/14 [==============================] - 1s 104ms/step - loss: 3.2910 - accuracy: 0.2243\n",
            "Epoch 19/30\n",
            "14/14 [==============================] - 1s 103ms/step - loss: 2.9744 - accuracy: 0.2746\n",
            "Epoch 20/30\n",
            "14/14 [==============================] - 1s 102ms/step - loss: 2.6539 - accuracy: 0.3432\n",
            "Epoch 21/30\n",
            "14/14 [==============================] - 1s 100ms/step - loss: 2.3332 - accuracy: 0.4376\n",
            "Epoch 22/30\n",
            "14/14 [==============================] - 2s 155ms/step - loss: 1.9954 - accuracy: 0.5320\n",
            "Epoch 23/30\n",
            "14/14 [==============================] - 2s 139ms/step - loss: 1.6556 - accuracy: 0.6299\n",
            "Epoch 24/30\n",
            "14/14 [==============================] - 1s 101ms/step - loss: 1.3742 - accuracy: 0.7237\n",
            "Epoch 25/30\n",
            "14/14 [==============================] - 1s 103ms/step - loss: 1.1948 - accuracy: 0.7626\n",
            "Epoch 26/30\n",
            "14/14 [==============================] - 1s 103ms/step - loss: 0.9095 - accuracy: 0.8484\n",
            "Epoch 27/30\n",
            "14/14 [==============================] - 1s 102ms/step - loss: 0.7636 - accuracy: 0.8690\n",
            "Epoch 28/30\n",
            "14/14 [==============================] - 1s 103ms/step - loss: 0.5314 - accuracy: 0.9376\n",
            "Epoch 29/30\n",
            "14/14 [==============================] - 1s 106ms/step - loss: 0.4799 - accuracy: 0.9388\n",
            "Epoch 30/30\n",
            "14/14 [==============================] - 2s 158ms/step - loss: 0.3291 - accuracy: 0.9662\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce3c437430>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"mymodel.h5\")"
      ],
      "metadata": {
        "id": "ACIq5q3EPczx"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"mymodel.h5\")"
      ],
      "metadata": {
        "id": "Jo8MGqH5PhgX"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(input_text, n_best):\n",
        "  input_text = input_text.lower()\n",
        "  x = np.zeros((1, n_words, len(unique_tokens)))\n",
        "  for i, word in enumerate(input_text.split()):\n",
        "    x[0, i, unique_tokens_index[word]] = 1\n",
        "  \n",
        "\n",
        "  predictions = model.predict(x)[0]\n",
        "  return np.argpartition(predictions, n_best)[n_best:]"
      ],
      "metadata": {
        "id": "FnMuP0ecPofw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "possible = predict_next_word(\"He will have to look into his thing as he\", 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVjeKjX9Qrma",
        "outputId": "df857ea4-f8c8-4214-f0e7-93744679e730"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 48ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([unique_tokens[idx] for idx in possible])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6qtSFp5RSzf",
        "outputId": "20c8c35c-2e9f-4966-a1c4-64f39a611705"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['don', 'right', 'results', 'plan', 'well', 'television', 'damaging', 'her', 'left', 'tenth', 'outcome', 'corruption', 'islam', 'got', 'often', 'retired', 'coy', 'crime', 'away', 'react', 'bigger', 'may', 'fundamental', 're', 'up', 'quickly', 'illegality', 'whatever', 'amendment', 'impropriety', 'but', 'cable', 'off', 'associates', 'any', 'and', 'years', 'you', 'bribery', 'no', 'destroy', 'clintonworld', 'possible', 'especially', 'come', 'illegal', 'entire', 'victory', 'credibility', 'weathered', 'other', 'them', 'stay', 'at', 'then', 'assaults', 'that', 'they', 'idea', 'pieces', 'back', 'playing', 'thing', 'those', 'hubris', 'bathroom', 'edgar', 'around', 'however', 'how', 'before', 'behavior', 't', 'establishment', 'belief', 'believes', 'longer', 'home', 'substance', 'thought', 'word', 'wing', 'threat', 'throughout', 'have', 'more', 'place', 'breeze', 'most', 'train', 'bring', 'whole', 'buried', 'truly', 'writer', 'try', 'even', 'james', 'hacks', 'spectrum', 'greenfield', 'york', 'smart', 'news', 'unfavorable', 'emails', 'glancing', 'gasoline', 'shillman', 'sexual', 'setup', 'claim', 'allegations', 'us', 'server', 'clearly', 'senator', 'security', 'usual', 'front', 'ahead', 'scandals', 'co', 'scandal', 'savage', 'same', 'now', 'freedom', 'vast', 'role', 'risk', 'instead', 'rigged', 'numerous', 'ride', 'conspiracies', 'conspiracy', 'obama', 'revelation', 'lead', 'followed', 'power', 'vytt49yvoe', 'war', 'warned', 'countless', 'respected', 'dnc', 'ads', 'cover', 'fireworks', 'republican', 'admits', 'remembered', 'knew', 'investigation', 'lambasting', 'display', 'preemptive', 'once', 'kind', 'explanation', 'recalls', 'days', 'debate', 'abuses', 'abedin', 'declare', 'pretending', 'abcpolitics', 'feigned', 'isn', 'federal', 'questions', 'denial', 'it', 'exposed', 'justified', 'procedural', 'near', 'filled', 'rating', 'daniel', 'currently', 'existence', 'cunning', 'courage', 'corrected', 'scene', 'center', 'over', 'mysterious', 'lived', 'targeting', 'https', 'huma', 'assault', 'asked', 'twitter', 'insisted', 'email', 'journalism', 'else', 'pinterest', 'poses', 'people', 'payroll', 'editorial', 'during', 'positive', 'dosed', 'paul', 'paranoid', 'panicked', 'exactly', 'done', 'exist', 'director', 'preemptively', 'development', 'procedure', 'pure', 'deny', 'original', 'option', 'fear', 'democratic', 'radical', 'fellow', 'opponent', 'fight', 'operation', 'figurehead', 'declaring', 'refused', 'final', 'old', 'fire', 'covert', 'flailing', 'republicans', 'could', 'wound', 'review', 'confident', 'foundation', 'running', 'com', 'close', 'claiming', 'november', 'changed', 'nothing', 'nonsense', 'short', 'globe', 'nobody', 'carville', 'nice', 'shrugged', 'new', 'smoke', 'space', 'campaign', 'spinmeisters', 'spouting', 'much', 'breezy', 'stored', 'mob', 'misguided', 'boston', 'world', 'might', 'headline', 'media', 'stories', 'strange', 'bizarre', 'wiretaps', 'himself', 'stretch', 'man', 'such', 'hoover', 'with', 'lot', 'sudden', 'survival', 'table', 'beds', 'wrong', 'batch', 'bad', 'hurt', 'than', 'lies', 'article', 'thrown', 'americans', 'level', 'information', 'two', 'unprecedented', 'violation', 'age', 'against', 'intimidation', 'way', 'wcvscg4a5i', 'weeks', 'irritating', 'kgb', 'what', 'abc', '60', 'without', '5', 'relevance', 'whether', 'jobs', 'just', 'j', 'its', 'keeping', 'is', 'investigators', 'into', 'know', '2016', 'lash', 'within', 'latest', 'interesting', 'leadership', 'leave', 'women', 'insane', 'letter', 'in', 'lie', 'if', 'like', '2020', 'linkedin', 'lit', 'house', 'loaded', 'locked', 'lofty', 'long', 'hour', 'look', 'hospital', 'loyalists', 'lunatic', 'lynch', 'hope', 'major', 'make', 'making', 'hit', 'him', 'hillary', 'match', 'here', 'meant', 'hell', 'mess', 'head', 'miles', 'hates', 'hatch', 'moment', 'months', 'moral', 'has', 'harry', 'msnbc', 'hard', 'happened', 'navigate', 'had', 'never', 'google', 'good', 'gone', 'going', 'go', 'nominee', 'given', 'not', 'gave', 'futures', 'from', 'form', 'for', 'of', 'focusing', 'focused', 'finding', 'on', 'film', 'one', 'only', 'fighting', 'few', 'fbi', 'or', 'fairly', 'exposing', 'ought', 'out', 'explosively', 'outdone', 'example', 'own', 'everyone', 'every', 'particularly', 'party', 'pass', 'patients', 'ever', 'enough', 'enjoys', 'personal', 'pic', 'picked', 'picking', 'energy', 'endorsement', 'emailing', 'election', 'elect', 'pocket', 'will', 'politics', 'either', 'down', 'doj', 'postured', 'do', 'practically', 'digg', 'didn', 'president', 'presidential', 'pretend', 'did', 'previously', 'principled', 'wikipedia', 'print', 'pro', 'desperation', 'desperately', 'prominent', 'promising', 'protecting', 'why', 'whose', 'published', 'desperate', 'push', 'putin', 'question', 'democrats', 'delicious', 'would', 'rally', 'ranks', 'declared', 'decides', 'decided', 'realdonaldtrump', 'reality', 'really', 'reason', 'day', 'recover', 'reddit', 'cycle', 'reid', 'criminal', 'relief', 'wouldn', 'remind', 'replaced', 'cowardice', 'course', 'resignation', 'country', 'respond', 'couldn', 'wreck', 'reveal', 'control', 'reversed', 'continue', 'conservative', 'computer', 'compared', 'ringing', 'comment', 'rodham', 'comey', 'coma', 'ryan', 's', 'column', 'colleagues', 'says', 'collapsed', 'cnn', 'closing', 'screwed', 'clintons', 'seemed', 'clinton', 'senior', 'sent', 'classified', 'circulated', 'sexism', 'chilly', 'she', 'charge', 'chances', 'shove', 'shown', 'careers', 'sigh', 'slightest', 'wreckage', 'smell', 'cards', 'sniveling', 'so', 'candidate', 'speaker', 'speakerryan', 'speaks', 'can', 'spinelessness', 'came', 'calling', 'stage', 'staggering', 'stand', 'start', 'bureau', 'states', 'breathing', 'step', 'still', 'bragged', 'born', 'boldly', 'strategy', 'bigotry', 'struggle', 'stumbleupon', 'between', 'better', 'believing', 'suddenly', 'supporting', 'surprising', 'surreal', 'being', 'behind', 'been', 'tak', 'taking', 'talked', 'tape', 'becoming', 'badly', 'backed', 'awkwardly', 'awkward', 'attacking', 'attacked', 'their', 'attack', 'assume', 'there', 'assaulting', 'as', 'this', 'arrogant', 'are', 'approach', 'through', 'appeaser', 'appearing', 'tied', 'time', 'times', 'to', 'today', 'too', 'appeared', 'trapped', 'trash', 'appearance', 'trump', 'truths', 'anywhere', 'trying', 'tumblr', 'turned', 'announced', 'also', 'ugly', 'unapologetic', 'uncomfortable', 'under', 'underway', 'already', 'unite', 'united', 'allowed', 'unscathed', 'until', 'allies', 'your', 'used', 'alive', 'utter', 'value', 'ago', 'very', 'agents', 'violating', 'agency', 'vladimir', 'volumes', 'vote', 'voted', 'afternoon', 'wake', 'waking', 'want', 'wants', 'after', 'afraid', 'warning', 'was', 'watching', 'ad', 'act', 'accusing', 'accused', 'weiner', 'aboutface', 'went', 'who', 'about', 'a', 'when', 'where', 'while', 'limp', 'which', 'were', 'statement', 'public', 'proved', 'principles', 'political', 'many', 'manages', 'wisconsin', 'made', 'last', 'keep', 'instant', 'his', 'he', 'defending', 'cravenly', 'coordinating', 'conviction', 'career', 'by', 'be', 'apolitical', 'anthony', 'an', 'all', 'zero']\n"
          ]
        }
      ]
    }
  ]
}
